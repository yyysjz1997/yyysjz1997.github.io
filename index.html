<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="robots" content="index, follow" />
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="keywords" content="Yiyuan Yang, Êù®ÊØÖËøú, time series, industrial signal processing, optical fiber sensors, deep learning, machine learning, Tsinghua University">
<link rel="stylesheet" href="./Files/jemdoc.css" type="text/css" />
<script src="jquery.min.js"></script>
<link rel="shortcut icon" href="./Files/favicon.ico">
<title>Yiyuan Yang (Êù®ÊØÖËøú)</title>
</head>
 

<body>

<a id="home" class="anchor"></a>
<div id="container"> 
<div class="container"> 

<table class="imgtable"><tr><td>
<a href="./"><img src="./Files/Yang_photo_2022.jpeg" alt="" height="210px" /></a>&nbsp;</td>

<td align="left"><p><font size="5">Yiyuan Yang </font><font size="5"; font style="font-family:Microsoft YaHei">Êù®ÊØÖËøú</font><font size="5"></font><br />

<a href="https://www.cs.ox.ac.uk/people/yiyuan.yang/" target="_blank">Official Website</a>
<br />
Ph.D. Candidate, <a href="https://www.cs.ox.ac.uk/" target="_blank">Department of Computer Science</a>, <a href="https://www.ox.ac.uk/" target="_blank">University of Oxford</a><br />
<br />
<class="staffshortcut">
 | <A HREF="#Home">Biography</A> | 
 <A HREF="#Interest">Research Interest</A> | 
 <A HREF="#Education and intern">Education and Intern</A> | 
 <A HREF="#Publications">Selected Publications</A> | 
 <A HREF="#Projects">Projects</A> | 
 <A HREF="#Honors and awards">Honors and Awards</A> |
 <A HREF="#Activities and volunteering">Activities and Services</A> | 
 <A HREF="#Invited talks and lives">Invited Talks and Lives</A> |
<br />
<br />
 
Email: yiyuan.yang@cs.ox.ac.uk (prior) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; yyy1997sjz@gmail.com  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; yangyy19@tsinghua.org.cn <br />

[<a href="https://scholar.google.com/citations?user=FUuGvZIAAAAJ&hl" target="_blank">Google Scholar</a>] 
[<a href="https://www.researchgate.net/profile/Yiyuan-Yang-3" target="_blank">ResearchGate</a>] 
[<a href="https://github.com/yyysjz1997" target="_blank">GitHub</a>] 
[<a href="https://www.linkedin.com/in/yiyuan-yang-8154941ab/" target="_blank">LinkedIn</a>]
[<a href="./Files/weixin.jpeg" target="_blank">Wechat</a>]
</td></tr></table>


<A NAME="Home"><h2>Biography</h2></A>
Yiyuan Yang is a D.Phil. (Ph.D.) student in the Department of Computer Science at the University of Oxford, specializing in data mining, time series, audio, signal processing, generative models, and large language models. His work focuses on real-world applications in healthcare, industrial sensors, energy, and traffic. He holds a master‚Äôs degree in the Department of Automation at Tsinghua University and a bachelor‚Äôs degree from the Experimental Class of the School of Artificial Intelligence and Automation & Qiming College at Huazhong University of Science and Technology. He has also gained valuable experience through internships at Alibaba DAMO Academy and Huawei Noah's Ark Lab.
<br /><br />
Yiyuan is an avid open-source contributor, with projects amassing over 30,000 GitHub stars. He has authored two bestselling books based on his tutorials and published over 20 papers in top conferences such as TKDE, KDD, NeurIPS, ACL, AAAI, IJCAI, TNNLS, CIKM, ICASSP, and Interspeech. He also serves as a reviewer for leading journals and conferences, including TPAMI, TKDE, TKDD, TIFS, TNNLS, TOMM, TCYB, TCSVT, TII, IoT, SPL, TITS, Neurocomputing, NeurIPS, KDD, WWW, AAAI, ACL, and SDM. In his free time, Yiyuan enjoys singing and participating in various sports.
</ul>

 
<A NAME="Interest"><h2>Research Interest</h2></A>
I work in the field of Intelligent sensing systems, Time series, LLM, Spatio-temporal data mining, Audio, Generative model, Machine learning, and Deep learning. Currently, I focus on the following research topics:
<ul>
<li>Spatio-temporal data mining and Distributed signal processing</li>
<li>Time series, Generative model, and LLM</li>
<li>Audio and Multimodal</li>
</ul>
<b>I love collaborating with others! If you're interested in working together, feel free to reach out ‚Äî don't hesitate!</b>üòäüòä


 
<A NAME="Education and intern"><h2>Education and Intern</h2></A>

<p><b>Education</b>: </p>
<ul>
<li>2023.01- &nbsp; D.Phil. in the <a href="https://www.cs.ox.ac.uk/" target="_blank">Department of Computer Science</a> at the <a href="https://www.ox.ac.uk/" target="_blank">University of Oxford</a> (<a href="https://www.merton.ox.ac.uk/" target="_blank">Merton College</a>), supervised by <a href="https://www.cs.ox.ac.uk/people/niki.trigoni/" target="_blank"> Profs. Niki Trigoni</a> and <a href="https://www.cs.ox.ac.uk/people/andrew.markham/" target="_blank">Andrew Markham</a>, with the fully-funded <a href="https://www.ox.ac.uk/clarendon" target="_blank">Clarendon Scholarship</a> and Merton College Scholarship.</li>
<li>2019.09-2022.07 &nbsp; Master's degree in the <a href="http://www.au.tsinghua.edu.cn/" target="_blank">Department of Automation</a> at the <a href="https://www.tsinghua.edu.cn/en/" target="_blank">Tsinghua University</a>. GPA 3.98/4.0, Rank 1/65.</li>
<li>2015.09-2019.06 &nbsp; Bachelor's degree in the <a href="http://aia.hust.edu.cn/" target="_blank">School of Artificial Intelligence and Automation</a> & Qiming College at the <a href="http://english.hust.edu.cn/" target="_blank">Huazhong University of Science and Technology</a>. (Honor Class on Innovation of Automation and Science) GPA 3.91/4.0.</li>
</ul>

<p><b>Intern & Exchange</b>: </p>
<ul>
<li>2025.06-2025.08 &nbsp; Research Intern in the Applied Sciences Group in Microsoft Research supervised by <a href="https://scholar.google.de/citations?user=UHUOlCwAAAAJ&hl=en" target="_blank">Dr. Soumitro Chakrabarty</a>. Focus on adaptive speech separation in conversational scenarios.</li>   
<li>2022.10-2023.02 &nbsp; Research Intern in the <a href="https://damo.alibaba.com/labs/decision-intelligence" target="_blank">Decision Intelligence Lab</a>-<a href="https://damo.alibaba.com/?lang=en" target="_blank">Alibaba DAMO Academy</a> supervised by <a href="https://sites.google.com/site/qingsongwen8/" target="_blank">Dr. Qingsong Wen</a> and <a href="https://scholar.google.com/citations?user=8JbrsgUAAAAJ&hl=en&oi=ao" target="_blank">Dr. Liang Sun</a>. Focus on Time series for anomaly detection.</li>   
<li>2021.02-2021.08 &nbsp; Research Intern in the Decision Making & Reasoning Lab-<a href="https://www.noahlab.com.hk/#/home" target="_blank">Huawei Noah's Ark Lab</a> supervised by <a href="https://scholar.google.com/citations?user=dXiVlkYAAAAJ" target="_blank">Dr. Qiquan Shi</a>,  <a href="https://xijunlee.github.io/" target="_blank">Dr. Xijun Li</a>, and <a href="https://sites.google.com/site/mingxuanhw/" target="_blank">Dr. Mingxuan Yuan</a>. Focus on graph and time series for forecasting and data mining.</li> 
<li>2019.01-2019.02 &nbsp; Exchange student in the Artificial intelligence field</a> at the <a href="https://www.cam.ac.uk/" target="_blank">University of Cambridge</a>.</li>
</ul>
<!-- <ul>
<li>2023.01- &nbsp; D.Phil. in the <a href="https://www.cs.ox.ac.uk/" target="_blank">Department of Computer Science</a> at the <a href="https://www.ox.ac.uk/" target="_blank">University of Oxford</a> (<a href="https://www.merton.ox.ac.uk/" target="_blank">Merton College</a>), supervised by <a href="https://www.cs.ox.ac.uk/people/niki.trigoni/" target="_blank"> Profs. Niki Trigoni</a> and <a href="https://www.cs.ox.ac.uk/people/andrew.markham/" target="_blank">Andrew Markham</a>, with the fully-funded <a href="https://www.ox.ac.uk/clarendon" target="_blank">Clarendon Scholarship</a> and Merton College Scholarship.</li>
<li>2022.10-2023.02 &nbsp; Research Intern in the <a href="https://damo.alibaba.com/labs/decision-intelligence" target="_blank">Decision Intelligence Lab</a>-<a href="https://damo.alibaba.com/?lang=en" target="_blank">Alibaba DAMO Academy</a> supervised by <a href="https://sites.google.com/site/qingsongwen8/" target="_blank">Dr. Qingsong Wen</a> and <a href="https://scholar.google.com/citations?user=8JbrsgUAAAAJ&hl=en&oi=ao" target="_blank">Dr. Liang Sun</a>. Focus on Time series for anomaly detection.</li>   
<li>2019.09-2022.07 &nbsp; Master's degree in the <a href="http://www.au.tsinghua.edu.cn/" target="_blank">Department of Automation</a> at the <a href="https://www.tsinghua.edu.cn/en/" target="_blank">Tsinghua University</a>. GPA 3.98/4.0, Rank 1/65.</li>
<li>2021.02-2021.08 &nbsp; Research Intern in the Decision Making & Reasoning Lab-<a href="https://www.noahlab.com.hk/#/home" target="_blank">Huawei Noah's Ark Lab</a> supervised by <a href="https://scholar.google.com/citations?user=dXiVlkYAAAAJ" target="_blank">Dr. Qiquan Shi</a>,  <a href="https://xijunlee.github.io/" target="_blank">Dr. Xijun Li</a>, and <a href="https://sites.google.com/site/mingxuanhw/" target="_blank">Dr. Mingxuan Yuan</a>. Focus on graph and time series for forecasting and data mining.</li> 
<li>2019.01-2019.02 &nbsp; Exchange student in the Artificial intelligence field</a> at the <a href="https://www.cam.ac.uk/" target="_blank">University of Cambridge</a>.</li>
<li>2015.09-2019.06 &nbsp; Bachelor's degree in the <a href="http://aia.hust.edu.cn/" target="_blank">School of Artificial Intelligence and Automation</a> & Qiming College at the <a href="http://english.hust.edu.cn/" target="_blank">Huazhong University of Science and Technology</a>. (Honor Class on Innovation of Automation and Science) GPA 3.91/4.0.</li>
</ul> -->

 
 


<A NAME="Publications"><h2>Selected Publications</h2></A>
Please see my full list at <a href="https://scholar.google.com/citations?user=FUuGvZIAAAAJ&hl" target="_blank">[Google Scholar Profile]</a>
<br /><br />

<p><b>Conferences</b>: </p>
<font size="3"> 
<ul>  

<p style="text-indent: -2.5rem;margin-left: 0rem;">
<span>[14] <b>Y. Yang</b>, S. Xu, N. Trigoni, A. Markham,
'Efficient and Microphone-Fault-Tolerant 3D Sound Source Localization,'
 <i><b>Interspeech 2025</b></i>
[<a href= "https://arxiv.org/pdf/2505.20961" target="_blank">ArXiv</a>]
</span>
</p> 
 
<p style="text-indent: -2.5rem;margin-left: 0rem;">
<span>[13] Y. Kong*, <b>Y. Yang*</b>, Y. Hwang, W. Du, S. Zohren, Z. Wang, M. Jin, Q. Wen,
'Time-MQA: Time Series Multi-Task Question Answering with Context Enhancement,'
 <i><b>ACL-Main 2025</b></i> 
[<a href= "https://arxiv.org/pdf/2503.01875" target="_blank">ArXiv</a>]
[<a href= "https://huggingface.co/datasets/Time-MQA/TSQA/blob/main/README.md" target="_blank">Dataset</a>]
</span>
</p> 

<p style="text-indent: -2.5rem;margin-left: 0rem;">
<span>[12] J. Wang, W. Du, <b>Y. Yang</b>, L. Qian, W. Cao, K. Zhang, W. Wang, Y. Liang, Q. Wen,
'Deep learning for multivariate time series imputation: A survey,'
 <i><b>IJCAI 2025</b></i> 
[<a href= "https://arxiv.org/abs/2402.04059" target="_blank">Link</a>]
[<a href= "https://github.com/WenjieDu/Awesome_Imputation" target="_blank">Github Repo</a>]
</span>
</p> 

<p style="text-indent: -2.5rem;margin-left: 0rem;">
<span>[11] C. Zhang, Y. Zhang, L. Peng, Q. Wen, <b>Y. Yang</b>, C. Fan, M. Jiang, L. Fan and L. Sun,  
'Advancing Multivariate Time Series Anomaly Detection: A Comprehensive Benchmark with Real-World Data from Alibaba Cloud,' 
 <i><b>CIKM 2024</b></i>
[<a href= "https://dl.acm.org/doi/10.1145/3627673.3679128" target="_blank">Link</a>]
[<a href= "https://github.com/KingsleyPattinson/AnomalyDetectionBenchmark" target="_blank">Code</a>]
[<a href= "https://figshare.com/articles/dataset/_b_BigDataAD_Benchmark_Dataset_b_/24040563" target="_blank">Dataset</a>]
</span>
</p>
 
<p style="text-indent: -2.5rem;margin-left: 0rem;">
<span>[10] <b>Y. Yang</b>, N. Trigoni, A. Markham,  
'Pre-training Feature Guided Diffusion Model for Speech Enhancement,' 
 <i><b>Interspeech 2024</b></i>
[<a href= "https://arxiv.org/abs/2406.07646" target="_blank">Arxiv</a>]
</span>
</p>
 
<p style="text-indent: -2.5rem;margin-left: 0rem;">
<span>[9] L Qian, Z Ibrahim, W Du, <b>Y. Yang</b>, R.JB Dobson, 
'Unveiling the Secrets: How Masking Strategies Shape Time Series Imputation,' 
 <i>IJCAI24 - AI4TS: AI for time series analysis workshop (<b>IJCAI Workshop 2024</b>) </i>
[<a href= "https://arxiv.org/abs/2405.17508" target="_blank">Arxiv</a>]
</span>
</p>

<p style="text-indent: -2.5rem;margin-left: 0rem;">
<span>[8] <b>Y. Yang</b>, K. Zhou, N. Trigoni, A. Markham, 
'SSL-Net: A Synergistic Spectral and Learning-based Network for Efficient Bird Sound Classification,' 
 <i><b>ICASSP 2024</b></i>
[<a href= "https://arxiv.org/abs/2309.08072" target="_blank">Arxiv</a>]
</span>
</p>
 
<p style="text-indent: -2.5rem;margin-left: 0rem;">
<span>[7] C.Zhu, <b>Y.Yang</b>, K. Yang, H. Zhang, Q. Yang, C. L. Philip Chen,
'AI-based Energy Transportation Safety: Pipeline Radial Threat Estimation using Intelligent Sensing System',
<i><b>AAAI 2024</b></i>
[<a href= "https://arxiv.org/abs/2312.11583" target="_blank">Arxiv</a>]
[<a href= "https://github.com/zhuchengyuan517/AAAI-7856-CODE" target="_blank">Code</a>]
[<a href= "https://github.com/zhuchengyuan517/AAAI-7856-DATA" target="_blank">Public Data</a>]
</span>
</p> 
 
<p style="text-indent: -2.5rem;margin-left: 0rem;">
<span>[6] K.Zhou, J.Zhong, S.Shin, K.Lu, <b>Y.Yang</b>, A.Markham, N.Trigoni,
'DynPoint: Dynamic Neural Point For View Synthesis',
<i><b>NeurIPS 2023</b></i>
[<a href= "https://arxiv.org/abs/2310.18999" target="_blank">ArXiv</a>]
[<a href= "https://github.com/kaichen-z/DynPoint" target="_blank">Code</a>]
[<a href= "./Files/DynPoint_poster.png" target="_blank">Poster</a>]
</span>
</p> 
 
<p style="text-indent: -2.5rem;margin-left: 0rem;">
<span>[5] <b>Y.Yang</b>, C.Zhang, T.Zhou, Q.Wen, L.Sun, 
'DCdetector: Dual Attention Contrastive Representation Learning for Time Series Anomaly Detection',
<i><b>KDD 2023</b></i>
[<a href= "https://arxiv.org/abs/2306.10347" target="_blank">ArXiv</a>]
[<a href= "https://github.com/DAMO-DI-ML/KDD2023-DCdetector" target="_blank">Code</a>]
[<a href= "https://www.youtube.com/watch?v=zjxSNNWJ9AE&list=PLn0nrSd4xjjaJCYKwjTdC7AvGrBKbu_yd&index=94" target="_blank">Video</a>]
[<a href= "./Files/Yang-DCdetector-poster.pdf" target="_blank">Poster</a>]
[<a href= "./Files/Yang-DCdetector-KDD2023.pdf" target="_blank">Slides</a>]
</span>
</p>

<p style="text-indent: -2.5rem;margin-left: 0rem;">
<span>[4] <b>Y.Yang</b>, R.Li, Q.Shi, X.Li, G.Hu, X.Li and M.Yuan,
'SGDP: A Stream-Graph Neural Network Based Data Prefetcher,' 
<i><b>IJCNN 2023</b></i>
[<a href= "https://arxiv.org/abs/2304.03864" target="_blank">ArXiv</a>]
[<a href= "./Files/Yang_2023_IJCNN.pdf" target="_blank">PDF</a>]
[<a href= "https://github.com/yyysjz1997/SGDP" target="_blank">Code</a>]
[<a href= "./Files/Yang-IJCNN2023-Slide.pdf" target="_blank">Slides</a>]
</span>
</p> 

<p style="text-indent: -2.5rem;margin-left: 0rem;">
<span>[3] X.Li, Q.Shi, G.Hu, L.Chen, H.Mao, <b>Y.Yang</b>, M.Yuan, J.Zeng and Z.Cheng,
'Block Access Pattern Discovery via Compressed Full Tensor Transformer,' 
<i><b>CIKM 2021</b></i>
[<a href= "https://dl.acm.org/doi/abs/10.1145/3459637.3482323" target="_blank">Link</a>]
[<a href= "https://dl.acm.org/doi/pdf/10.1145/3459637.3482323" target="_blank">PDF</a>]
</span>
</p> 
 
<p style="text-indent: -2.5rem;margin-left: 0rem;">
<span>[2] <b>Y. Yang</b>, Y. Li, H. Zhang, 
'Pipeline Safety Early Warning Method for Distributed Signal using Bilinear CNN and LightGBM,' 
<i><b>ICASSP 2021</b></i> 
[<a href="https://ieeexplore.ieee.org/document/9414544" target="_blank">Link</a>]
[<a href="./Files/Yang_2021_ICASSP.pdf" target="_blank">PDF</a>]
[<a href="./Files/Yang_2021_ICASSP_poster.pdf" target="_blank">Poster</a>] 
[<a href="https://ieeeicassp-virtual.org/presentation/poster/pipeline-safety-early-warning-method-distributed-signal-using-bilinear-cnn-and" target="_blank">Slides</a>] 
[<a href="https://ieeeicassp-virtual.org/presentation/poster/pipeline-safety-early-warning-method-distributed-signal-using-bilinear-cnn-and" target="_blank">Video</a>] 
</span>
</p>

<p style="text-indent: -2.5rem;margin-left: 0rem;">
<span>[1] <b>Y. Yang</b>, Y. Li, T. Zhang, Y. Zhou, and H. Zhang, 
'Early Safety Warnings for Long-Distance Pipelines: A Distributed Optical Fiber Sensor Machine Learning Approach,' 
<i><b>AAAI 2021</b></i>
[<a href="https://ojs.aaai.org/index.php/AAAI/article/view/17759" target="_blank">Link</a>]
[<a href="./Files/Yang_2021_AAAI.pdf" target="_blank">PDF</a>]
[<a href= "./Files/Yang_2021_ICASSP_poster.pdf" target="_blank">Poster</a>] 
[<a href="https://virtual.2021.aaai.org/paper_AISI-2820.html" target="_blank">Slides</a>] 
[<a href="https://virtual.2021.aaai.org/paper_AISI-2820.html" target="_blank">Video</a>] 
</span>
</p>
</ul>
</font>


<p><b>Journals</b>: </p>
<font size="3"> 
<ul>

<p style="text-indent: -2.5rem;margin-left: 0rem;">
<span>[8] Z.Zhong, Z.Yu, <b>Y.Yang</b>, W.Wang, K.Yang,
'PatchAD: A Lightweight Patch-based MLP-Mixer for Time Series Anomaly Detection,' 2025.
<i>IEEE Transactions on Big Data (<b>IEEE T BIG DATA</b>)</i>, 
2025.
(<b>Q1, IF=5.7</b>) 
[<a href= "https://arxiv.org/abs/2401.09793" target="_blank">Paper</a>]
[<a href= "https://github.com/EmorZz1G/PatchAD" target="_blank">Code</a>]
</span>
</p> 

<p style="text-indent: -2.5rem;margin-left: 0rem;">
<span>[7] Z. Zhong, Z. Yu, X. Xi, Y. Xu, W. Cao, J. Chen, <b>Y. Yang</b>, K. Yang,
'SimAD: A Simple Dissimilarity-based Approach for Time Series Anomaly Detection,'
<i>IEEE Transactions on Neural Networks and Learning Systems (<b>TNNLS</b>)</i>, 
2025.
(<b>Q1, IF=14.255</b>) 
[<a href= "https://arxiv.org/abs/2405.11238" target="_blank">Paper</a>]
[<a href= "https://github.com/EmorZz1G/SimAD" target="_blank">Code</a>]
</span>
</p> 

<p style="text-indent: -2.5rem;margin-left: 0rem;">
<span>[6] Z. Z. Darban, <b>Y. Yang</b>, G. I. Webb, C. C. Aggarwal, Q. Wen, M. Salehi,
'DACAD: Domain Adaptation Contrastive Learning for Anomaly Detection in Multivariate Time Series,'
<i>IEEE Transactions on Knowledge and Data Engineering (<b>TKDE</b>)</i>, 
2025.
(<b>Q1, IF=10.4</b>) 
[<a href= "https://arxiv.org/abs/2404.11269" target="_blank">Paper</a>]
[<a href= "https://github.com/zamanzadeh/DACAD" target="_blank">Code</a>]
</span>
</p> 

<p style="text-indent: -2.5rem;margin-left: 0rem;">
<span>[5] S. Du, H. Zhang, C. Gong, <b>Y. Yang</b>, X. Jiang, L. Zhou, T. Zhang, Y. Ma, J. Meng, Y. Li, 
'A Pipeline Inspection Gauge Positioning Method Based on Distributed Fiber Optic Vibration Sensing,' 
<i>IEEE Sensors Journal (<b>IEEE SENS J</b>)</i>, 
2024.
(<b>Q1, IF=4.776</b>) 
[<a href= "https://ieeexplore.ieee.org/abstract/document/10719668" target="_blank">Link</a>]
</span>
</p>
 
<p style="text-indent: -2.5rem;margin-left: 0rem;">
<span>[4] C. Gong*, <b>Y. Yang*</b>, H. Zhang, J. Meng, Y. Ma, S. Du, Y. Li, 
'A Pipeline Intrusion Detection Method Based on Temporal Modeling and Hierarchical Classification in Optical Fiber Sensing,' 
<i>IEEE Sensors Journal (<b>IEEE SENS J</b>)</i>, 
2024.
(<b>Q1, IF=4.776, equal contribution</b>) 
[<a href= "https://ieeexplore.ieee.org/abstract/document/10508302" target="_blank">Link</a>]
</span>
</p>

<p style="text-indent: -2.5rem;margin-left: 0rem;">
<span>[3] C. Zhu, Y. Pu, <b>Y. Yang</b>, Z. Lyu, C. Li, Q. Yang, 
'Localizing and tracking of in-pipe inspection robots based on distributed optical fiber sensing,' 
<i>Advanced Engineering Informatics (<b>AEI</b>)</i>, 
2024.
(<b>Q1, IF=9.9</b>) 
[<a href= "https://www.sciencedirect.com/science/article/pii/S1474034624000727" target="_blank">Link</a>]
[<a href= "Files/Yang_2024_AEI.pdf" target="_blank">PDF</a>]
</span>
</p>

 
<p style="text-indent: -2.5rem;margin-left: 0rem;">
<span>[2] <b>Y. Yang</b>, H. Zhang, Y. Li, 
'Pipeline Safety Early Warning by Multi-feature-fusion CNN and LightGBM Analysis of Signals from Distributed Optical Fiber Sensors,' 
<i>IEEE Transactions on Instrumentation and Measurement (<b>IEEE T INSTRUM MEAS</b>)</i>, 
2021.
(<b>Q1, IF=5.9</b>) 
[<a href= "https://ieeexplore.ieee.org/document/9541184" target="_blank">Link</a>]
[<a href= "Files/Yang_2021_TIM.pdf" target="_blank">PDF</a>]
</span>
</p>

<p style="text-indent: -2.5rem;margin-left: 0rem;">
<span>[1] <b>Y. Yang</b>, H. Zhang, Y. Li, 
'Long-Distance Pipeline Safety Early Warning: A Distributed Optical Fiber Sensing Semi-Supervised Learning Method,' 
<i>IEEE Sensors Journal (<b>IEEE SENS J</b>)</i>, 
2021.
(<b>Q1, IF=4.776</b>) 
[<a href= "https://ieeexplore.ieee.org/abstract/document/9448237" target="_blank">Link</a>] 
[<a href= "Files/Yang_2021_IEEE_sensors_J.pdf" target="_blank">PDF</a>]
</span>
</p>
</ul>
</font>


<p><b>Book</b>: </p>
<font size="3"> 
<ul>

<p style="text-indent: -2.5rem;margin-left: 0rem;">
<span>[3] J. Jiang, Q. Wang, <b>Y. Yang</b>,
'Joy-RL: Reinforcement Learning Practical Tutorial' &nbsp; <a href= "./Files/Yang_2025_mogu.jpg" target="_blank">(Joy-RLÔºöÂº∫ÂåñÂ≠¶‰π†ÂÆûË∑µÊïôÁ®ã)</a>, Posts & Telecom Press, 2025.
[<a href= "https://github.com/datawhalechina/joyrl-book" target="_blank">GitHub Repo</a>]
[<a href= "https://datawhalechina.github.io/joyrl-book/" target="_blank">E-book</a>]
[<a href= "https://github.com/datawhalechina/joyrl" target="_blank">code</a>]
[<a href= "https://item.jd.com/14990878.html" target="_blank">Jingdong</a>]
</span>
</p>
 
<p style="text-indent: -2.5rem;margin-left: 0rem;">
<span>[2] Q. Wang, <b>Y. Yang</b>, J. Jiang, 
'LeeDL-Tutorial' &nbsp; <a href= "./Files/Yang_2024_pingguo.jpg" target="_blank">(Ê∑±Â∫¶Â≠¶‰π†ËØ¶Ëß£)</a>, Posts & Telecom Press, 2024. <b><font color="#FF0000">(JD 2024 Annual Best Books (All the Top 50), ‰∫¨‰∏ú2024Âπ¥Â∫¶Â•Ω‰π¶ and Excellent new book for 2024 in PTP, ‰∫∫Ê∞ëÈÇÆÁîµÂá∫ÁâàÁ§æÂπ¥Â∫¶ÂΩ±ÂìçÂäõÊñ∞‰π¶)</font></b>
[<a href= "https://github.com/datawhalechina/leedl-tutorial" target="_blank">GitHub Repo</a>]
[<a href= "https://github.com/datawhalechina/leedl-tutorial/releases" target="_blank">E-book</a>]
[<a href= "https://book.douban.com/subject/36997460/" target="_blank">Douban</a>]
[<a href= "https://product.dangdang.com/29766946.html" target="_blank">Dangdang</a>] 
[<a href= "https://item.jd.com/14245179.html" target="_blank">Jingdong</a>]
</span>
</p>
 
<p style="text-indent: -2.5rem;margin-left: 0rem;">
<span>[1] Q. Wang, <b>Y. Yang</b>, J. Jiang, 
'Easy-RL: Reinforcement Learning Tutorial' &nbsp; <a href= "./Files/Yang_2022_mougu.png" target="_blank">(Easy-RLÔºöÂº∫ÂåñÂ≠¶‰π†ÊïôÁ®ã)</a>, Posts & Telecom Press, 2022. <b><font color="#FF0000">(Excellent book for 2022 in PTP)</font></b>
[<a href= "https://github.com/datawhalechina/easy-rl" target="_blank">GitHub Repo</a>]
[<a href= "https://datawhalechina.github.io/easy-rl" target="_blank">Online version</a>]
[<a href= "https://github.com/datawhalechina/easy-rl/releases" target="_blank">E-book</a>]
[<a href= "https://book.douban.com/subject/35781275" target="_blank">Douban</a>]
[<a href= "https://detail.tmall.com/item.htm?spm=a230r.1.14.63.73f8bf5d3pzHU3&id=669396714456&ns=1&abbucket=17" target="_blank">Taobao</a>] 
[<a href= "http://product.dangdang.com/29374163.html" target="_blank">Dangdang</a>] 
[<a href= "https://item.jd.com/13075567.html" target="_blank">Jingdong</a>]
</span>
</p>
</ul>
</font>

 
<p><b>PrePrint</b>: </p>
<font size="3"> 
<ul>

<p style="text-indent: -2.5rem;margin-left: 0rem;">
<span>[7] <b>Y. Yang</b>, Z. Liu, L. Song, K. Ying, Z. Wang, T. Bamford, S. Vyetrenko, J. Bian, Q. Wen
'Time-RA: Towards Time Series Reasoning for Anomaly with LLM Feedback,' 2025.
[<a href= "https://arxiv.org/pdf/2507.15066" target="_blank">ArXiv</a>]
[<a href= "https://github.com/yyysjz1997/Time-RA" target="_blank">Code</a>]
[<a href= "https://huggingface.co/datasets/Time-RA/RATs40K/tree/main" target="_blank">Dataset</a>]
</span>
</p> 
 
<p style="text-indent: -2.5rem;margin-left: 0rem;">
<span>[6] W. Du, <b>Y. Yang</b>, L. Qian, J. Wang, Q. Wen
'PyPOTS: A Python Toolkit for Machine Learning on Partially-Observed Time Series,' 2025.
[<a href= "https://arxiv.org/pdf/2305.18811" target="_blank">ArXiv</a>]
[<a href= "https://pypots.com/" target="_blank">Website</a>]
[<a href= "https://github.com/WenjieDu/PyPOTS" target="_blank">Repo</a>]
</span>
</p> 
 
<p style="text-indent: -2.5rem;margin-left: 0rem;">
<span>[5] S. Xu, <b>Y. Yang</b>, N. Trigoni, A. Markham,
'Target Speaker Extraction through Comparing Noisy Positive and Negative Audio Enrollments,' 2025.
[<a href= "https://arxiv.org/pdf/2502.16611" target="_blank">ArXiv</a>]
</span>
</p> 
 
<p style="text-indent: -2.5rem;margin-left: 0rem;">
<span>[4] Y. Kong*, <b>Y. Yang*</b>, S. Wang, C. Liu, Y. Liang, M. Jin, S. Zohren, D. Pei, Y. Liu, Q. Wen,
'Position: Empowering Time Series Reasoning with Multimodal LLMs,' 2025.
[<a href= "https://arxiv.org/abs/2502.01477" target="_blank">ArXiv</a>]
</span>
</p> 
 
<p style="text-indent: -2.5rem;margin-left: 0rem;">
<span>[3] <b>Y. Yang</b>, Z. Wu, Y. Chu, Z. Chen, Z. Xu, Q. Wen,
'Intelligent Cross-Organizational Process Mining: A Survey and New Perspectives,' 2024.
[<a href= "https://arxiv.org/abs/2407.11280v1" target="_blank">ArXiv</a>]
</span>
</p> 
 
<p style="text-indent: -2.5rem;margin-left: 0rem;">
<span>[2] W. Du*, J. Wang*, L. Qian*, <b>Y. Yang*</b>, F. Liu, Z. Wang, Z. Ibrahim, H. Liu, Z. Zhao, Y. Zhou, W. Wang, K. Ding, Y. Liang, B. A. Prakash, Q. Wen,
'TSI-Bench: Benchmarking Time Series Imputation,' 2024.
[<a href= "https://arxiv.org/abs/2406.12747" target="_blank">ArXiv</a>]
[<a href= "https://github.com/wenjiedu/awesome_imputation" target="_blank">Code</a>]
</span>
</p> 
 
<p style="text-indent: -2.5rem;margin-left: 0rem;">
<span>[1] <b>Y. Yang</b>, M. Jin, H. Wen, C. Zhang, Y. Liang, L. Ma, Y. Wang, C. Liu, B. Yang, Z. Xu, J. Bian, S. Pan, Q. Wen,
'A Survey on Diffusion Models for Time Series and Spatio-Temporal Data,' 2024.
[<a href="https://arxiv.org/abs/2404.18886" target="_blank">ArXiv</a>]
[<a href="https://github.com/yyysjz1997/Awesome-TimeSeries-SpatioTemporal-Diffusion-Model" target="_blank">Github Repo</a>]
</span>
</p>


<!--
<p style="text-indent: -2.5rem;margin-left: 0rem;">
<span>[1] C. Wang, R. Zhang, H. Zhang, <b>Y. Yang</b>, J. Meng, Y. Ma, 
'Distributed Fiber Optic Warning Identification Algorithm for Oil and Gas Pipelines Based on the Inception-Dvs Model,' 2023. 
[<a href= "https://arxiv.org/abs/2401.09793" target="_blank">SSRN</a>]
</span>
</p>
-->
 
</ul>
</font>

<!--
<p><b>Workshops, Posters and Others</b>: </p>
<font size="3"> 
<ul> 
<p style="text-indent: -2.5rem;margin-left: 0rem;">
<span>[4] <b>Y.Yang</b>, H.Zhang, Y.Li,
'PSEW system based on semi-supervised learning and distributed optical fiber,' 
<i>The 14th Doctoral Candidate Nanshan Academic Forum of Guangdong-Hong Kong-Macau Grand Bay District & No. 670 Doctoral Forum, Tsinghua University</i>, Shenzhen, China, 2022. (<b>Poster</b>) </li>
[<a href="./Files/Yang_2022_nanshanboshi_Poster.pdf" target="_blank">PDF</a>] 
</span>
</p> 

<p style="text-indent: -2.5rem;margin-left: 0rem;">
<span>[3] <b>Y.Yang</b>, Y.Li and H.Zhang,
'Long-Distance Pipeline Safety Early Warning: A Distributed Optical Fiber Sensor Deep Learning Approach,' 
<i>IEEE the 6th Optoelectronics Global Conference (<b>OGC 2021</b>)</i>, 
2021. (<b>Abstract & Oral</b>)
[<a href="./Files/Yang_2021_OGC.pdf" target="_blank">PDF</a>] 
[<a href="./Files/Yang_2021_OGC_oral.jpg" target="_blank">Picture_oral</a>] 
[<a href="./Files/Yang_2021_OGC_oral_ppt.pdf" target="_blank">Slide</a>] 
</span>
</p> 
 
<p style="text-indent: -2.5rem;margin-left: 0rem;">
<span>[1] <b>Y. Yang</b>,
'Long-distance Oil and Gas Transportation Pipeline Safety Early Warning System Based on Deep Learning Approach,' 
<i>The XVII International Forum-Contest of Students and Young Researchers Topical Issues of Rational Use of Natural Resources</i>, 
in Saint Petersburg, Russia, 2021. 
(<b>Abstract & Oral & First prize</b>)
[<a href="http://myouth.spmi.ru/en" target="_blank">Link</a>]
[<a href="./Files/Yang_2021_Russia.pdf" target="_blank">PDF</a>] 
[<a href="./Files/Yang_2021_Russia_Certification.pdf" target="_blank">Certification</a>] 
[<a href="./Files/Yang_2021_Russia_Certification_winner.pdf" target="_blank">Certification for Winner</a>] 
</span>
</p>
 
<p style="text-indent: -2.5rem;margin-left: 0rem;">
<span>[1] <b>Y. Yang</b>, H. Zhang, Y. Li, 
'Pipeline safety warning system based on distributed optical fiber sensing,' 
<i>The 13th Doctoral Candidate Nanshan Academic Forum of Guangdong-Hong Kong-Macau Grand Bay District & No. 635 Doctoral Forum, Tsinghua University</i>, Shenzhen, China, 2021. 
(<b>Abstract & Oral & First prize</b>) 
[<a href="./Files/Yang_2021_SGO.pdf" target="_blank">PDF</a>]  
</span>
</p>
</ul>
</font>
-->


<!-- <p><b>Patents</b>: </p>
<font size="3"> 
<ul>
 
<p style="text-indent: -2.5rem;margin-left: 0rem;">
<span>[3] "A Patent on Time Series Anomaly Detection", a patent application.
</span>
</p> 
 
<p style="text-indent: -2.5rem;margin-left: 0rem;">
<span>[2] <b>Y. Yang</b>, H. Zhang, Y. Li, 
'A method for feature extraction of optical fiber warning signals for oil and gas long-distance pipelines', Chinese invention patents, 2021.
</span>
</p>

<p style="text-indent: -2.5rem;margin-left: 0rem;">
<span>[1] M. Zhang, G. Wu, Y. Li, <b>Y. Yang</b>, 
'A complex multi-frequency real-time capacitance tomography imaging method based on multiple measurement vectors', Chinese invention patents, 2020.
</span>
</p>
</ul>
</font> -->


<A NAME="Projects"><h2>Projects</h2></A>

<font size="3"> 
<ul>

<!-- <li><a href= "https://github.com/datawhalechina/leedl-tutorial" target="_blank"><b>LeeDL-Tutorial</b>:</a> A Chinese deep learning tutorial and it has already collected <b><font color="#FF0000">13,000 more stars and 2,900 forks</font></b> on GitHub, which includes an 
    <a href= "https://github.com/datawhalechina/leedl-tutorial/releases" target="_blank">an e-book</a> and 
    <a href= "https://github.com/datawhalechina/leedl-tutorial/tree/master/Homework" target="_blank">codes</a>. Here are some links to our book. 
    [<a href= "https://book.douban.com/subject/36997460/" target="_blank">Douban</a>] 
    [<a href= "https://product.dangdang.com/29766946.html" target="_blank">Dangdang</a>] 
    [<a href= "https://item.jd.com/14245179.html" target="_blank">Jingdong</a>]
</li> -->
<li>
    <a href="https://github.com/datawhalechina/leedl-tutorial" target="_blank"><b>LeeDL-Tutorial</b>:</a> 
    A Chinese deep learning tutorial and it has already collected <b><font color="#FF0000" id="star-count">stars</font></b> and 
    <b><font color="#FF0000" id="fork-count">forks</font></b> on GitHub, which includes an 
    <a href="https://github.com/datawhalechina/leedl-tutorial/releases" target="_blank">an e-book</a> and 
    <a href="https://github.com/datawhalechina/leedl-tutorial/tree/master/Homework" target="_blank">codes</a>. Here are some links to our book. 
    [<a href="https://book.douban.com/subject/36997460/" target="_blank">Douban</a>] 
    [<a href="https://product.dangdang.com/29766946.html" target="_blank">Dangdang</a>] 
    [<a href="https://item.jd.com/14245179.html" target="_blank">Jingdong</a>]
    <br><font size="2">
    Our book topped the list of AI-field New books on Jingdong for about 30 days. The paper version won the Excellent new book for 2024 in PTP and JD 2024 Annual Best Book (all the top 50).
    </font></br>
</li>

<script>
    async function updateGitHubData() {
        try {
            const response = await fetch('https://api.github.com/repos/datawhalechina/leedl-tutorial');
            const data = await response.json();
            const starCount = data.stargazers_count;
            const forkCount = data.forks_count;

            document.getElementById('star-count').innerText = `${starCount} stars`;
            document.getElementById('fork-count').innerText = `${forkCount} forks`;
        } catch (error) {
            console.error('Error fetching GitHub data:', error);
        }
    }

    updateGitHubData();
</script>
 
<li>
    <a href="https://github.com/datawhalechina/easy-rl" target="_blank"><b>Easy-RL</b>:</a>
    A reinforcement learning tutorial and it has already collected <b><font color="#FF0000" id="easy-rl-star-count">stars</font></b> and
    <b><font color="#FF0000" id="easy-rl-fork-count">forks</font></b> on GitHub, which includes
    <a href="https://github.com/datawhalechina/easy-rl/releases" target="_blank">an e-book</a> and
    <a href="https://datawhalechina.github.io/easy-rl" target="_blank">an online tutorial</a>. Also, there is
    <a href="https://aistudio.baidu.com/aistudio/education/group/info/27444" target="_blank">an online tutorial</a> collaboration with Baidu PaddlePaddle AI Studio, and <b>more than 2,000 learners</b> participated in this class. Here are some links to our book.
    [<a href="https://book.douban.com/subject/35781275" target="_blank">Douban</a>]
    [<a href="https://detail.tmall.com/item.htm?spm=a230r.1.14.63.73f8bf5d3pzHU3&id=669396714456&ns=1&abbucket=17" target="_blank">Taobao</a>]
    [<a href="http://product.dangdang.com/29374163.html" target="_blank">Dangdang</a>]
    [<a href="https://item.jd.com/13075567.html" target="_blank">Jingdong</a>]
    <br><font size="2">
    Our book topped the list of new computer books on Dangdang and the list of AI-field New books on Jingdong within ten days. The number of related tweet reads exceeded 100,000, and it was recommended to the libraries of the North China Electric Power University, Shanghai Ocean University, Tsinghua University. Also, <font color="#FF0000">it is included in the <a href="http://www.nlc.cn/" target="_blank">National Library of China</a></font>, Library of Tsinghua University, Library of Shanghai Jiao Tong University, Library of Zhejiang University, Library of Chinese Academy of Sciences, Library of Oxford Merton College, and so on. The electronic version has been downloaded over 10,000 times, and the paper version won the PTP key book selection and Excellent book for 2022 Q1th in PTP.
    </font></br>
</li>

<li>
    <a href="https://github.com/datawhalechina/team-learning-data-mining/tree/master/AcademicTrends" target="_blank"><b>Academic Trends Analysis</b>:</a>
    A data-mining-based tutorial on the analysis of academic trends of arxiv platform. I am the main person in charge. Here is
    <a href="https://tianchi.aliyun.com/course/live/1602" target="_blank">a video</a> and
    <a href="https://tianchi.aliyun.com/competition/entrance/531866/introduction" target="_blank">a competition</a> on Alibaba Tianchi platform. <b>More than 4,300 teams</b> participated in this competition. Here are some introductions about our tutorial.
    [<a href="./Files/AcademicTrends_Analysis_poster.jpg" target="_blank">Poster</a>]
    [<a href="https://mp.weixin.qq.com/s/EPORF-OdQ4cLH1y1foLIHw" target="_blank">Link1</a>]
    [<a href="https://mp.weixin.qq.com/s/t1w7bSWnT4bn99__A0zf_Q" target="_blank">Link2</a>]
</li>

<li>
    <a href="https://github.com/datawhalechina/team-learning-data-mining/tree/master/EnsembleLearning" target="_blank"><b>Ensemble Learning</b>:</a>
    An ensemble learning tutorial. There is
    <a href="https://www.bilibili.com/video/BV1R54y137Q5?p=38" target="_blank">a video</a> of the case study and an introduction to our tutorial.
    [<a href="https://t.bilibili.com/134239128?type=2" target="_blank">Link</a>]
</li>

<script>
    async function updateGitHubData(repo, starId, forkId) {
        try {
            const response = await fetch(`https://api.github.com/repos/${repo}`);
            const data = await response.json();
            document.getElementById(starId).innerText = `${data.stargazers_count} stars`;
            document.getElementById(forkId).innerText = `${data.forks_count} forks`;
        } catch (error) {
            console.error('Error fetching GitHub data:', error);
        }
    }

    // Update GitHub star and fork counts for each repository
    updateGitHubData('datawhalechina/easy-rl', 'easy-rl-star-count', 'easy-rl-fork-count');
    // Add similar calls for other repositories if needed
</script>

<!-- <li><a href= "https://github.com/datawhalechina/easy-rl" target="_blank"><b>Easy-RL</b>:</a> A reinforcement learning tutorial and it has already collected <b><font color="#FF0000">9,500 more stars and 1,900 forks</font></b> on GitHub, which includes
    <a href= "https://github.com/datawhalechina/easy-rl/releases" target="_blank">an e-book</a> and 
    <a href= "https://datawhalechina.github.io/easy-rl" target="_blank">an online tutorial</a>. Also, there is <a href= "https://aistudio.baidu.com/aistudio/education/group/info/27444" target="_blank">an online tutorial</a> collaboration with Baidu PaddlePaddle AI Studio, and <b>more than 2,000 learners</b> participated in this class. Here are some links to our book. 
    [<a href= "https://book.douban.com/subject/35781275" target="_blank">Douban</a>] 
    [<a href= "https://detail.tmall.com/item.htm?spm=a230r.1.14.63.73f8bf5d3pzHU3&id=669396714456&ns=1&abbucket=17" target="_blank">Taobao</a>] 
    [<a href= "http://product.dangdang.com/29374163.html" target="_blank">Dangdang</a>] 
    [<a href= "https://item.jd.com/13075567.html" target="_blank">Jingdong</a>]
    <br><font size="2">
    Our book topped the list of new computer books on Dangdang and the list of AI-field New books on Jingdong within ten days. The number of related tweet reads exceeded 100,000, and it was recommended to the libraries of the North China Electric Power University, Shanghai Ocean University, SIGS at Tsinghua University. Also, <font color="#FF0000">it is included in the <a href= "http://www.nlc.cn/" target="_blank">National Library of China</a></font>, Library of Tsinghua University, Library of Shanghai Jiao Tong University, Library of Zhejiang University, Library of Chinese Academy of Sciences, and so on. The electronic version has been downloaded over 10,000 times, and the paper version won the PTP key book selection and Excellent book for 2022 Q1th in PTP.
    </font></br>
</li>

<li><a href= "https://github.com/datawhalechina/team-learning-data-mining/tree/master/AcademicTrends" target="_blank"><b>Academic Trends Analysis</b>:</a> A data-mining-based tutorial on the analysis of academic trends of arxiv platform. I am the main person in charge. Here is 
    <a href= "https://tianchi.aliyun.com/course/live/1602" target="_blank">a video</a> and 
    <a href= "https://tianchi.aliyun.com/competition/entrance/531866/introduction" target="_blank">a competition</a> on Alibaba Tianchi platform. <b>More than 4,300 teams</b> participated in this competition. Here are some introductions about our tutorial.
    [<a href= "./Files/AcademicTrends_Analysis_poster.jpg" target="_blank">Poster</a>] 
    [<a href= "https://mp.weixin.qq.com/s/EPORF-OdQ4cLH1y1foLIHw" target="_blank">Link1</a>] 
    [<a href= "https://mp.weixin.qq.com/s/t1w7bSWnT4bn99__A0zf_Q" target="_blank">Link2</a>] 
</li>

<li><a href= "https://github.com/datawhalechina/team-learning-data-mining/tree/master/EnsembleLearning" target="_blank"><b>Ensemble Learning</b>:</a> An ensemble learning tutorial. There is 
    <a href= "https://www.bilibili.com/video/BV1R54y137Q5?p=38" target="_blank">a video</a> of the case study and an introduction to our tutorial.
    [<a href= "https://t.bilibili.com/134239128?type=2" target="_blank">Link</a>]  
</li> -->

<!--
<li>Original and translated articles in the field of data science are as follows. [<a href= "https://mp.weixin.qq.com/s/rX5bXdLKsLXHojE-Uns1lA" target="_blank">SVPÔºöAn efficient data selection method for deep learning</a>]
[<a href= "https://mp.weixin.qq.com/s/nnOi5zkM8xcnsADuveby8g" target="_blank">Four types of classification tasks in machine learning</a>]
[<a href= "https://mp.weixin.qq.com/s/tKfsNDEi7o-4ILmzltPGMQ" target="_blank">Handling missing values in data</a>]
[<a href= "https://mp.weixin.qq.com/s/1mkt2cCYiRa8mQpnmSXO1g" target="_blank">Deriving decision tree algorithms</a>]
[<a href= "https://mp.weixin.qq.com/s/2owCuV7Cis6LqbD4_BC-4A" target="_blank">NLP-based COVID-19 Fake News Detection</a>]
[<a href= "https://mp.weixin.qq.com/s/gYAh1542NFKOrKnfvnpsNg" target="_blank">Original | AI-based intelligent detection of acute intracranial haemorrhage types</a>]
</li>

<li>More open-source contents can be found on my <a href= "https://yangyy97.blog.csdn.net/" target="_blank">CSDN</a> and <a href= "https://github.com/yyysjz1997?tab=repositories" target="_blank">GitHub</a>.
</li>
-->
</ul>
</font>

 
 
<!-- <p><b>Research Projects</b>: </p>
<font size="3"> 
<ul>

<li>2023, Conducted research on time-series anomaly detection for industry application in the Decision Intelligence Lab-Alibaba DAMO Academy.
</li> 
 
<li>2021, Conducted research on workload I/O time-series prediction for storage systems in Decision Making & Reasoning Lab, Huawei Noah's Ark Lab. The work has the potential for practical implementation in the storage products of Huawei.
</li> 

<li>2021, 'Long-distance Oil and Gas Transportation Pipeline Safety Early Warning System Based on Deep Learning Approach,' 
<i>The XVII International Forum-Contest of Students and Young Researchers Topical Issues of Rational Use of Natural Resources</i>, 
in Saint Petersburg, Russia, 2021. 
(<b>Abstract & Oral & First prize</b>)
[<a href="http://myouth.spmi.ru/en" target="_blank">Link</a>]
[<a href="./Files/Yang_2021_Russia.pdf" target="_blank">PDF</a>] 
[<a href="./Files/Yang_2021_Russia_Certification.pdf" target="_blank">Certification</a>] 
[<a href="./Files/Yang_2021_Russia_Certification_winner.pdf" target="_blank">Certification for Winner</a>]
</li> 

<li>2020, Teaching assistant of <a href= "http://niclane.org/" target="_blank">Nicholas Lane</a>, the professor in the Department of Computer Science at the <a href= "https://www.cam.ac.uk/" target="_blank">University of Cambridge</a>, UK. The class name is 'Introduction to Deep Learning'.
    [<a href= "./Files/Yang_2020_Cam.pdf" target="_blank">Certification</a>] 
</li>

<li>2020, Teaching assistant of <a href= "http://passat.crhc.illinois.edu/" target="_blank">Rakesh Kumar</a>, the professor of the Department of Electrical and Computer Engineering at the <a href= "https://ece.illinois.edu/" target="_blank">UIUC</a>, USA. The class name is 'Artificial Intelligence for Undergraduate'.
    [<a href= "./Files/Yang_2020_UIUC.pdf" target="_blank">Certification</a>] 
</li>
 
<li>2019-2022, Research on long-distance optical fiber safety monitoring and pipeline safety early warning technology in complex environments with PetroChina and Tsinghua University. The system has been used in a Chinese pipeline for about 2 years.[<a href= "./Files/Yang_2020_winter_PSEW.jpeg" target="_blank">Picture</a>] </li>

<li>2020, Vehicle license plate recognition <a href= "https://github.com/yyysjz1997/Vehicle-License-Plate-Recognition-VLPR-without-DL-and-ML" target="_blank"><b>(VLPR)</b></a> without DL and ML methods.</li>

<li>2019, <a href= "https://github.com/yyysjz1997/SIGS-Convex2019-project" target="_blank"><b>Inter-prediction for Multiview video coding</b></a> by using Convex Optimization.
    [<a href= "./Files/Yang_2019_convex.pdf" target="_blank">PDF</a>] 
    [<a href= "./Files/Yang_2019_convex.pptx" target="_blank">Slides</a>] 
</li>

<li>2019, A project named 'Find-Future-Fun', using big data, AI and robot to accompany teenagers to grow up.
    [<a href= "./Files/Yang_2019_xunqu_video.mp4" target="_blank">Video</a>] 
    [<a href= "./Files/Yang_2019_xunqu.jpeg" target="_blank">Picture</a>] 
</li> -->






</ul>
</font>
<A NAME="Honors and awards"><h2>Honors and Awards</h2></A>
<font size="3"> 
<ul>
<li>2025, Interspeech2025 Conference Travel Grants.</li> 
<li>2025, Graduate Research Grant, Merton College, University of Oxford.</li> 
<li>2024, 2024 Excellent New Book (Ê∑±Â∫¶Â≠¶‰π†ËØ¶Ëß£) and Influential Author, <a href= "https://www.epubit.com/" target="_blank">Epubit</a>, PTPress, and JD 2024 Annual Best Book (all the top 50).</li>
<li>2023, 2022 Bestselling Book (Easy-RLÔºöÂº∫ÂåñÂ≠¶‰π†ÊïôÁ®ã) and Influential Author, <a href= "https://www.epubit.com/" target="_blank">Epubit</a>, PTPress.[<a href= "https://mp.weixin.qq.com/s/qq5Ked9fYERNgP4iPigR4Q" target="_blank">Link</a>][<a href= "./Files/2023_Yang_EasyRL_bestyearbook.jpg" target="_blank">Picture1</a>][<a href= "./Files/2023_Yang_bestyearauthor.jpg" target="_blank">Picture2</a>][<a href= "./Files/Yang-2023-EasyRLPTP1.jpeg" target="_blank">Certification</a>][<a href= "./Files/Yang-2023-EasyRLPTP2.jpeg" target="_blank">Trophy</a>]</li>
<li>2022, <a href= "https://www.ox.ac.uk/clarendon/offer-holders/scholars-association" target="_blank">Clarendon Scholar</a>, University of Oxford.</li>  
<li><b><font color="#FF0000">2022, Outstanding Graduate, Beijing.</font></b></li>    
<li>2022, Outstanding Master's Thesis, Tsinghua University.</li>  
<li>2022, Outstanding Graduate, Department of Automation, Tsinghua University.</li>
<!-- <li>2022, 'ZhiZhuo Honor' and 'ZhiXin Honor' of <a href= "https://datawhale.club/" target="_blank">Datawhale</a>. [<a href= "./Files/Yang_2022_Dw_zhizhuo.jpeg" target="_blank">ZhiZhuo</a>][<a href= "./Files/Yang_2022_Dw_zhixin.jpeg" target="_blank">ZhiXin</a>]</li>  -->
<li>2022, Internship First-class Scholarship, SIGS, Tsinghua University. (15,000 CNY)</li>
<li>2022, Excellent book's author for 2022 Q1th in PTP, China. [<a href= "./Files/Yang_2022_xibao.jpeg" target="_blank">Picture</a>]</li>
<!-- <li>2022, Outstanding volunteer of the Wechat Media Platform "Data Pai-THU". [<a href= "https://mp.weixin.qq.com/s/q861LzYoqqeCoU4gp6pdIw" target="_blank">Link</a>]</li> -->
<!-- <li>2021, Social Work Scholarship, SIGS, Tsinghua University. </li> -->  
<li><b><font color="#FF0000"> 2021, China National Scholarship.</font></b></li> 
<li>2021, <a href= "https://datawhale.club/" target="_blank">Datawhale</a> Contributor.</li> 
<li>2020, National Second Prize in the 17th National Postgraduate Mathematical Modelling Competition.</li>  
<li>2020, Second-class Scholarship, Tsinghua University.</li>
<li>2020, Kaggle Competitions Expert, Ranking Top 1,000 (0.67%).</li>
<!-- <li>2020, Member of the Outstanding team of the Tsinghua University Postgraduate Anti-epidemic Service Team.</li> -->
<li>2019, Outstanding Graduate, Huazhong University of Science and Technology.</li>
<li>2018, First Prize in the 13th National Student Smart Car Competition, Wireless Energy Saving Category (<b><font color="#FF0000">National Champion</font></b>).</li>
<li>2018, First-class (Grand prize) Goodix Scholarship Ôºà15,000 CNYÔºâ.</li>
<li>2018, National Encouragement Scholarship, Ministry of Education in China.</li>
<!-- <li>2018, Outstanding Individual of Innovation and Entrepreneurship Activities, Huazhong University of Science and Technology.</li> -->
<li>2017, First Prize in South China of the 12th National Student Smart Car Competition, Optoelectronic Balance Category.</li>
</ul>
</font>

<A NAME="Activities and volunteering"><h2>Activities and Services</h2></A>
<font size="3"> 
<ul>
<li>Reviewer of ACL 2025.</li>
<li>Reviewer of WWW 2025.</li>
<li>Reviewer of AAAI 2023, 2024, 2025, and 2026.</li>
<li>Reviewer of SIGKDD 2023 and 2024.</li>
<li>Reviewer of NeurIPS 2023, 2024, and 2025.</li>
<li>Reviewer of SDM 2024.</li>
<li>Program Committee Member of <a href= "https://kdd-milets.github.io/milets2023/" target="_blank">9th&10th SIGKDD workshop on Mining and Learning from Time Series (MILETS)</a>.</li>
<li>Technical Program Committee Member of IJCNN2023, 2024, 2025.</li>
<br>
<li>Reviewer of Engineering Applications of Artificial Intelligence (EAAI).</li>
<li>Reviewer of ACM Transactions on Intelligent Systems and Technology (TIST).</li>
<li>Reviewer of Knowledge-Based Systems (KBS).</li>
<li>Reviewer of IEEE Transactions on Industrial Informatics (TII).</li>
<li>Reviewer of IEEE Internet of Things Journal (IoT).</li>
<li>Reviewer of IEEE Transactions on Intelligent Transportation Systems (TITS).</li>
<li>Reviewer of IEEE Signal Processing Letters (SPL).</li>
<li>Reviewer of IEEE Journal of Biomedical and Health Informatics (JBHI).</li>
<li>Reviewer of ACM Transactions on Knowledge Discovery from Data (TKDD).</li>
<li>Reviewer of Neurocomputing.</li>
<li>Reviewer of IEEE Transactions on Circuits and Systems for Video Technology (TCSVT).</li>
<li>Reviewer of IEEE Transactions on Cybernetics (TCYB).</li>
<li>Reviewer of IEEE Transactions on Circuits and Systems I: Regular Papers (TCASI).</li>
<li>Reviewer of IEEE Transactions on Neural Networks and Learning Systems (TNNLS).</li>
<li>Reviewer of ACM Transactions on Multimedia Computing Communications and Applications (TOMM).</li>
<li>Reviewer of Journal of Medical Internet Research.</li>
<li>Reviewer of IEEE Transactions on Information Forensics & Security (TIFS).</li>
<li>Reviewer of IEEE Transactions on Knowledge and Data Engineering (TKDE).</li>
<li>Reviewer of IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI).</li>
<li>Reviewer of IEEE/CAA Journal of Automatica Sinica.</li>
<br>
<li>2025.02, Co-leader of the <a href= "https://intelligent-earth.ox.ac.uk/" target="_blank">iECDT</a> Deep Learning Course, University of Oxford.</li>
<li>2024.04-06, Teaching Assistant of ‚ÄùMachine Learning‚Äù lecture at Department of Computer Science Oxford.</li>
<li>2024.04-06, Teaching Assistant of ‚ÄùArtificial Intelligence‚Äù lecture at Department of Computer Science Oxford.</li>
<li>2020, Teaching assistant of <a href= "http://niclane.org/" target="_blank">Nicholas Lane</a> from <a href= "https://www.cam.ac.uk/" target="_blank">University of Cambridge</a> about 'Introduction to Deep Learning'.</li>
<li>2020, Teaching assistant of <a href= "http://passat.crhc.illinois.edu/" target="_blank">Rakesh Kumar</a> from <a href= "https://ece.illinois.edu/" target="_blank">UIUC</a> about 'Artificial Intelligence for Undergraduate'.</li>
<!-- <li>2022.07-Now, <a href= "http://www.aitime.cn/" target="_blank">AI Time member</a>, sharing the AI future and recent researches. </li> -->
<br>
<li>2023.03-2024.03, <a href= "https://mertonmcr.co.uk/" target="_blank">MCR</a> Social Secretary in Merton College, University of Oxford.</li>
<li>2020.06-Now, <a href= "https://datawhale.club/" target="_blank">Datawhale member</a> (an open-source AI organization), helped data science fans get involved in the AI community.</li>
<!-- <li>2020, During the Covid-19 epidemic, as a volunteer of the Tsinghua University Graduate Student Association's anti-epidemic activities, I provided one-to-one support to a child of frontline medical staff in Wuhan for her study.</li> -->
<!-- <li>2020, During the Covid-19 epidemic, I recorded an original song 'Into the Spring' with TAP Choir. [<a href= "https://mp.weixin.qq.com/s/8mug1M1XVKXfzVVczobTSg" target="_blank">News</a>]</li>  -->
<li>2019-2022, Member of the Tsinghua University Shenzhen TAP Choir.</li>
<li>2019, Debate chairman of the Shenzhen government-sponsored university debate tournament. [<a href= "./Files/Yang_2019_debate.png" target="_blank">Picture</a>]</li> 
<!-- <li>2019, Member of the Tsinghua University Shenzhen TAP Choir, participating in the 'Ode to the Motherland' performance in Shenzhen (at Shenzhen Grand Theater). [<a href= "./Files/Yang_2019_ZGS.jpg" target="_blank">Picture</a>] [<a href= "./Files/Yang_2019_ZGS_2.jpg" target="_blank">Picture</a>]</li>  -->
<!-- <li>2019, LINK Project, SIGS, Tsinghua University.
    [<a href= "https://mp.weixin.qq.com/s/PhICmpvVPa_9FmxlFI6hLA" target="_blank">Link1</a>]
    [<a href= "https://mp.weixin.qq.com/s/LNlt1EhkH-2vu5Bk5l2Y9A" target="_blank">Link2</a>]
    [<a href= "https://mp.weixin.qq.com/s/sPOTX3wr_JKoFtyZ1YF-DA" target="_blank">Link3</a>]
</li>  -->
<!-- <li>2018, Participants representing more than 100 universities took the oath at the 13th National Student Smart Car Competition South China Region. [<a href= "https://mp.weixin.qq.com/s/c4zsLmw7cPiQu2CXrkNxzA" target="_blank">News</a>]</li>  -->
<li>2017, Top 10 Singers of the School of Artificial Intelligence and Automation, HUST.
    [<a href= "https://mp.weixin.qq.com/s/YTVqZu-4K57TxGNujTE6GQ" target="_blank">Link</a>]
</li>  
<li>2015-2019, Member of the College's hosting team and hosted two welcome parties and a graduation party.</li> 
</ul>
</font>

<A NAME="Invited talks and lives"><h2>Invited Talks and Lives</h2></A>
<font size="3"> 
<ul>
<li>2024.12, A talk about "New Concepts, Methods, and Directions of AI-Enabled Digital Courses," organized by Beijing Normal University.
</li> 
<li>2024.08, A talk about time series and artificial intelligence at 1st Computational Decision Neuroscience (CDN) Summer School and Decision Neuroscience Symposium.
    [<a href= "https://mp.weixin.qq.com/s/mnjlHVaZtpJOkhdLBPeSGQ" target="_blank">Link</a>]
</li> 
<li>2024.05, AI+X University Tour in Northwestern Polytechnical University, Datawhale.
    [<a href= "https://mp.weixin.qq.com/s/4J1WlRyCtT-VlYcBC3toqw" target="_blank">Link1</a>]
    [<a href= "https://mp.weixin.qq.com/s/L-0R9ExgLyN3JI_HXP03OA" target="_blank">Link2</a>]
    [<a href= "https://mp.weixin.qq.com/s/LT_TGZC5mBVcTPa-4i3KoQ" target="_blank">Link3</a>]
</li> 
<li>2024.04, AI+X University Tour in Tsinghua University, Datawhale.
    [<a href= "https://mp.weixin.qq.com/s/Pzvnr43OAAAEAgcTnB-pdw" target="_blank">Link</a>]
</li> 
<li>2024.04, A PhD debate live about Mamba at AItime.
    [<a href= "https://mp.weixin.qq.com/s/6uEFW0HnizDr4F705HcYNw" target="_blank">Link1</a>]
    [<a href= "https://mp.weixin.qq.com/s/By0xmyAHk1x8ag0bv2anFA" target="_blank">Link2</a>]
</li> 
<li>2024.01, A PhD debate live about Agent at AItime.
    [<a href= "https://www.bilibili.com/video/BV165411q7gX/?spm_id_from=333.337.search-card.all.click" target="_blank">Video</a>]
</li> 
<li>2023.07, A KDD paper sharing presentation at AItime.
    [<a href= "https://www.bilibili.com/video/BV18M4y1s7UN/?spm_id_from=333.337.search-card.all.click&vd_source=642fa389e9e78cff4881c038963ac312" target="_blank">Video</a>]
    [<a href= "https://mp.weixin.qq.com/s/N3OkPlCQwN_c5sxxOZFy2A" target="_blank">Link</a>]
    [<a href= "./Files/Yang-KDDAITIME-2023.jpg" target="_blank">Picture</a>]
</li> 
<li>2023.07, A presentation at WAIC 2023 Shanghai.
    [<a href= "https://mp.weixin.qq.com/s/9-TE0dFngwRg4MmwYSoyIA" target="_blank">Link1</a>]
    [<a href= "https://mp.weixin.qq.com/s/TpCpH0JViv4J6NOea3-Rig" target="_blank">Link2</a>]
    [<a href= "./Files/Yang-WAIC1-2023.jpg" target="_blank">Picture1</a>]
    [<a href= "./Files/Yang-WAIC2-2023.jpg" target="_blank">Picture2</a>]
    [<a href= "https://www.bilibili.com/video/BV13x4y197ZN/?spm_id_from=333.788&vd_source=642fa389e9e78cff4881c038963ac312" target="_blank">Video</a>]
</li> 
<li>2023.07, An EASY-RL Book Sharing at WAIC 2023 Shanghai.
    [<a href= "https://mp.weixin.qq.com/s/aJukezDwfGISMnSYU1qArQ" target="_blank">Link</a>]
    [<a href= "./Files/Yang-WAIC3-2023.jpg" target="_blank">Picture</a>]
</li> 
<li>2023.06, A presentation at Oxford Computer Science Conference 2023.
    [<a href= "https://www.cs.ox.ac.uk/teaching/dphil/schedule.pdf" target="_blank">Link</a>]
</li> 
<li>2023.02, An experience sharing article.
    [<a href= "https://mp.weixin.qq.com/s/UkxYEznCKzqTw2eOCCCrUw" target="_blank">Link</a>]
</li> 
<li>2022.11, A video about Easy-RL and open-source.
    [<a href= "https://www.bilibili.com/video/BV1i84y1t7uA/?spm_id_from=333.1007.top_right_bar_window_default_collection.content.click&vd_source=642fa389e9e78cff4881c038963ac312" target="_blank">Link</a>]
</li> 
<li>2022.11, A live stream about introduction of AI and ML.
    [<a href= "./Files/Yang_IntroAIML.jpeg" target="_blank">Poster</a>]
</li>  
<li>2022.11, <a href= "https://aistudio.baidu.com/aistudio/education/group/info/27444" target="_blank">An online tutorial</a> collaboration with Baidu PaddlePaddle AI Studio (2,000 more participants).
    [<a href= "https://mp.weixin.qq.com/s/NME5FTJ2620pSP867SPgFA" target="_blank">Link1</a>]
    [<a href= "https://mp.weixin.qq.com/s/NF365pEUV3Z9Y_GlN3E6pA" target="_blank">Link2</a>]
    [<a href= "./Files/Yang_baidu_paddle.jpeg" target="_blank">Picture1</a>]
    [<a href= "./Files/Yang_baidu_paddle2.jpeg" target="_blank">Picture2</a>]
</li>  
<li>2022.10, Experience Sharing in the SIGS, Tsinghua University.
    [<a href= "https://mp.weixin.qq.com/s/IDYyGDE0mIogtbES_HmIbw" target="_blank">Link1</a>]
</li>     
<li>2022.09, A live stream about Open Source in the <a href= "http://www.aitime.cn/" target="_blank">AI Time</a>.
    [<a href= "https://mp.weixin.qq.com/s/2BZpccwPmAIu446Cm81DYw" target="_blank">Link1</a>]
    [<a href= "https://mp.weixin.qq.com/s/dhRBjchqYu2R3a1alXt5Lw" target="_blank">Link2</a>]
    [<a href= "https://mp.weixin.qq.com/s/FIulkNTsNMYCOqjc-OWc5Q" target="_blank">Link3</a>]
    [<a href= "./Files/Yang_2022_AITime_1.jpg" target="_blank">Picture1</a>]
    [<a href= "./Files/Yang_2022_AITime_2.jpeg" target="_blank">Picture2</a>]
</li>  
<li>2022.09, New Students Experience Sharing in the SIGS, Tsinghua University.
</li>    
<li>2022.09, Invited Talk in the <a href= "https://www.worldaic.com.cn/" target="_blank">2022 World Artificial Intelligence Conference</a>. (Dishui Lake AI Developer Innovation Forum)
    [<a href= "https://online2022.worldaic.com.cn/forumdetail?uuid=c412de9a58604519940f06cac98fd1fb&type=video" target="_blank">Video1</a>]
    [<a href= "https://www.bilibili.com/video/BV1xW4y1B72o?spm_id_from=333.1007.top_right_bar_window_custom_collection.content.click&vd_source=642fa389e9e78cff4881c038963ac312" target="_blank">Video2</a>]
    [<a href= "https://mp.weixin.qq.com/s/xQwPAt6750uShbCiaAXV0w" target="_blank">Link1</a>]
    [<a href= "https://mp.weixin.qq.com/s/d-xrmlGXz28SJsM-VaJLeg" target="_blank">Link2</a>]
    [<a href= "https://mp.weixin.qq.com/s/2I_tp4K3rkEeAPTT1dXgww" target="_blank">Link3</a>]
    [<a href= "https://mp.weixin.qq.com/s/1br3Xs5-t2UjgH-wqEF04g" target="_blank">Link4</a>]
</li>
<li>2022.09, Invited Talk in the <a href= "https://www.worldaic.com.cn/" target="_blank">2022 World Artificial Intelligence Conference</a>. (<a href= "http://www.aiwin.org.cn/" target="_blank">AIWIN</a> 5th Anniversary Gala and "AI Developer Nurturing and Growth" Forum)
    [<a href= "https://online2022.worldaic.com.cn/forumdetail?uuid=ea28f4bd2a6b466d90345d2a8d4d7b12&type=video" target="_blank">Video</a>]
    [<a href= "https://mp.weixin.qq.com/s/-q6T8cBOk6n4VRlhduZKMA" target="_blank">Link1</a>]
    [<a href= "https://mp.weixin.qq.com/s/8XuF2O_nmArDGJBpE7xjgw" target="_blank">Link2</a>]
</li>
<li>2022.08, Internal Invited Talk in the <a href= "http://www.aitime.cn/" target="_blank">AI Time</a>.
</li>
<li>2022.08, Graduate interview/story, SIGS, Tsinghua University.
    [<a href= "https://mp.weixin.qq.com/s/e7yCVMBkmw9G0CTeViM_kQ" target="_blank">Link1</a>]
    [<a href= "https://mp.weixin.qq.com/s/3tkRXxXQPXeV90py2NF_Aw" target="_blank">Link2</a>]
    [<a href= "https://mp.weixin.qq.com/s/E4sHhiWZCihdIPpgrD78TQ" target="_blank">Link3</a>]
</li>
<li>2022.07, Bilibili Programmers read classic IT books.
    [<a href= "https://mp.weixin.qq.com/s/bM42g9uQxdbSG6edP243Og" target="_blank">Link</a>] 
    [<a href= "https://www.bilibili.com/video/BV1Dr4y1M7VR?spm_id_from=333.999.0.0" target="_blank">Video1</a>] 
    [<a href= "https://www.bilibili.com/video/BV1yv4y1M7Mj?spm_id_from=333.999.0.0&vd_source=642fa389e9e78cff4881c038963ac312" target="_blank">Video2</a>]
    [<a href= "https://www.bilibili.com/video/BV1Dr4y1M7VR?spm_id_from=333.999.0.0&vd_source=642fa389e9e78cff4881c038963ac312" target="_blank">Video3</a>] 
    [<a href= "https://www.bilibili.com/video/BV1qF411c79X?spm_id_from=333.999.0.0&vd_source=642fa389e9e78cff4881c038963ac312" target="_blank">Video4</a>] 
    [<a href= "./Files/Yang_2022_Bilibili.jpeg" target="_blank">Picture</a>]
</li>
<li>2022.05, Wechat Media Platform "Gu-Yue-Ju" Easy-RL book live sharing.
    [<a href= "https://mp.weixin.qq.com/s/a4Imkewd-Isrbo5hmf-faw" target="_blank">Link1</a>] 
    [<a href= "https://mp.weixin.qq.com/s/Vyecxr3M22MpgzUq4DlhDA" target="_blank">Link2</a>] 
    [<a href= "./Files/Yang_2022_Guyueju.jpg" target="_blank">Picture</a>]
</li>
<li>2022.05, Ph.D application experience sharing on "Bright Top" Forum.</li>
<li>2022.05, "Bright Top" Forum Easy-RL book live sharing.</li>
<li>2022.04, Easy-RL book live sharing with Posts and Telecommunications Press.
    [<a href= "https://mp.weixin.qq.com/s/IjVGT56U6mWuNUOyBpa_3w" target="_blank">Link1</a>] 
    [<a href= "https://mp.weixin.qq.com/s/-Iu9YfFD5y1qeEaSiyy0TQ" target="_blank">Link2</a>] 
    [<a href= "https://mp.weixin.qq.com/s/K7Ued8dJ23gIy6B51dN7Ag" target="_blank">Link3</a>] 
    [<a href= "https://mp.weixin.qq.com/s/0EPoHUyj-tbQvvWLALBvHw" target="_blank">Link4</a>]
    [<a href= "https://mp.weixin.qq.com/s/Oki4RLBjWDRHt02tEn5p6g" target="_blank">Link5</a>] 
    [<a href= "https://mp.weixin.qq.com/s/X78pucoPq4RJTkDV4hGykg" target="_blank">Link6</a>] 
    [<a href= "https://mp.weixin.qq.com/s/svAmAiP2JAs8k_qBbvrLGw" target="_blank">Link7</a>] 
    [<a href= "https://mp.weixin.qq.com/s/VHhb3QCXHmwuOaaAMn9u7w" target="_blank">Link8</a>]
    [<a href= "https://mp.weixin.qq.com/s/F88p--uG3T3kOzEzxnJXEQ" target="_blank">Link9</a>]
    [<a href= "https://mp.weixin.qq.com/s/5mMkjJlldIIUbnV3D6ZFrw" target="_blank">Link10</a>] 
    [<a href= "https://mp.weixin.qq.com/s/nrDVH11ZHhRpg-a2v-d6CQ" target="_blank">Link11</a>] 
    [<a href= "https://mp.weixin.qq.com/s/xfwZOSOc9BCXigsS8RwnAA" target="_blank">Link12</a>] 
    [<a href= "https://mp.weixin.qq.com/s/f2yJGOof0X-VQUjvjVePkw" target="_blank">Link13</a>]
    [<a href= "https://mp.weixin.qq.com/s/pTo2QkxsfdCZcFN5bBglcg" target="_blank">Link14</a>] 
    [<a href= "https://mp.weixin.qq.com/s/zfaiATqU2PC0OYHNSeenvA" target="_blank">Link15</a>] 
    [<a href= "https://mp.weixin.qq.com/s/DX6x_F_DjzoQ-D0K9h4HXw" target="_blank">Link16</a>]
    [<a href= "https://mp.weixin.qq.com/s/3FZ0ZGQBYWwUm0voJwM_Mg" target="_blank">Link17</a>]
    [<a href= "https://mp.weixin.qq.com/s/WUSCpS1We3XNFp_wBrNrhQ" target="_blank">Link18</a>] 
    [<a href= "https://mp.weixin.qq.com/s/UP81cFbF73yZ-CWyqcXIgA" target="_blank">Link19</a>] 
    [<a href= "https://mp.weixin.qq.com/s/wAxKF1M5Z4Sy7C-kWG-RJA" target="_blank">Link20</a>]
    [<a href= "./Files/Yang_2022_easyrl1.png" target="_blank">Picture1</a>]
    [<a href= "./Files/Yang_2022_easyrl2.jpeg" target="_blank">Picture2</a>]
    [<a href= "./Files/Yang_2022_easyrl3.jpeg" target="_blank">Picture3</a>]
    [<a href= "./Files/Yang_2022_easyrl4.jpeg" target="_blank">Picture4</a>]
    [<a href= "./Files/Yang_2022_easyrl5.jpeg" target="_blank">Picture5</a>]
    [<a href= "./Files/Yang_2022_easyrl6.jpeg" target="_blank">Picture6</a>]
    [<a href= "./Files/Yang_2022_easyrl7.jpeg" target="_blank">Picture7</a>]
    [<a href= "./Files/Yang_2022_easyrl8.jpeg" target="_blank">Picture8</a>]
    [<a href= "./Files/Yang_2022_easyrl9.png" target="_blank">Picture9</a>]
    [<a href= "./Files/Yang_2022_easyrl10.png" target="_blank">Picture10</a>]
    [<a href= "./Files/Yang_2022_easyrl11.png" target="_blank">Picture11</a>]
    [<a href= "./Files/Yang_2022_easyrl12.png" target="_blank">Picture12</a>]
</li>
<li>2022.03, Easy-RL book recommendation video.
    [<a href= "https://mp.weixin.qq.com/s/DX6x_F_DjzoQ-D0K9h4HXw" target="_blank">Link1</a>]
    [<a href= "https://mp.weixin.qq.com/s/f2yJGOof0X-VQUjvjVePkw" target="_blank">Link2</a>]
    [<a href= "https://www.bilibili.com/video/BV1rb4y1x7Zd?spm_id_from=333.1007.top_right_bar_window_default_collection.content.click" target="_blank">Video</a>]
</li>
<li>2021.11, China National Scholarship Sharing meeting, SIGS, Tsinghua University.
    [<a href= "https://mp.weixin.qq.com/s/zpTlWnmxoq6DxQ3lRCBmzQ" target="_blank">Link1</a>]
    [<a href= "https://mp.weixin.qq.com/s/PgZix8hhdDNsdV3-tIm0uQ" target="_blank">Link2</a>]
</li>
<li>2021.08, Internship academic sharing, Smart Storage Group, Huawei.</li>
<li>2021.05, Ensemble learning tutorial live Q&A and case sharing, Datawhale.
    [<a href= "https://mp.weixin.qq.com/s/MTQROZIz4kqq9Pcmp1syvA" target="_blank">Link</a>]
    [<a href= "https://www.bilibili.com/video/BV1R54y137Q5?p=38" target="_blank">Video</a>]
</li>
<li>2021.01, Competition "Academic Trend Analysis" baseline live sharing, Alibaba Tianchi.
    [<a href= "https://mp.weixin.qq.com/s/EPORF-OdQ4cLH1y1foLIHw" target="_blank">Link</a>]
    [<a href= "https://tianchi.aliyun.com/course/live/1602" target="_blank">Video</a>]
</li>

</ul>
</font>

<script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=080808&w=500&t=n&d=dJDHJ3-hyo0XeVx6oc7STY3ihPbjvz2CHCOP4-j6XOo&co=ffffff&cmo=3acc3a&cmn=ff5353&ct=808080'></script>
 
<div id="article"></div>
<div id="back_top">
<div class="arrow"></div>
<div class="stick"></div>
</div>






<!--
All Rights Reserved by Yiyuan Yang. Part of page is generated by <a href="http://jemdoc.jaboc.net/">jemdoc</a>.
-->

<!--
<font size="2"; color="#A0A0A0";>
<p style="text-align:center">Updating time: 2021.08.29</p>
</font>
-->

</body>
</html>
